<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>PAC Portfolio</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="css/agency.min.css" rel="stylesheet">
    <link href="css/agency.css" rel="stylesheet">

    <!-- favicon --> 

    <link rel="icon" href="img/pac-icon.png">

  </head>

  <body id="page-top">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="/index.html">PAC</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fa fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav text-uppercase ml-auto">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="/index.html#about">About</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="https://okiyuki.github.io/ARCportfolio/public/portfolio.html">Portfolio</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="index.html#team">Team</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="index.html#contact">Contact</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Header -->
    <header class="masthead">
      <div class="container">
        <div class="intro-text">
          <div class="intro-heading text-uppercase">Portfolio</div>
          <div class="intro-lead-in">Our Process</div>
        </div>
      </div>
    </header>

    <div class="container">
    <br>
    <br>

    <h2>Background</h2>
    <p>In September of 2017, the four of us enrolled in COGS160: Civic Design taught by Steven Dow at UC San Diego. The focus on this class would be entering into Design for San Diego's 2017 Civic Challenge and after the challenge was over to continually iterate on our design.</p>
    <p>The focus of D4SD’s 2017 challenge was: How do we create a San Diego where we all move freely? Judging was conducted in two rounds. In the first, experts in human-centered design, civics, and business assessed our deliverables based on four criteria: human-centered design process, novelty, feasibility, and impact. In the second, distinguished jurors assessed the finalists.</p> 
    <p>For the D4SD challenge, we conducted online research, five hours of total field observations between us, and interviews. For our deliverables, we created a poster and prototype and wrote a high-level description of our solution. </p>
    <p>After the D4SD challenge, we reflected on the experience and the feedback provided by the judges. From this, we created a usable prototype and tested it. After testing, we iterated on our concept and presented our refined prototype to panel of judges invited to the UC San Diego campus by Steven Dow.</p>
    <div class="cent">
        <img src="img/d4sd.jpg" width="600">
        <br><br>
        <p>Our team attending Design Forward's Community Mixer on October 25th where our poster was displayed.  From left to right: Marie Schneider, Yuka Okina, Alexander Chen, Tamar Esserman.</p>
    </div>

    <hr>
    <h2>Our Focus</h2>
    <p>Last year there were 307 fatal car crashes in San Diego. According to KPBS, more than twice as many people have died from car crashes in San Diego than have been murdered. There are 15 intersections in San Diego, named the Fatal 15, where more than 200 people have been killed or seriously injured.</p>
    <p>Due to this, we decided to tackle was the issue of safety in busy intersections. How do we leverage existing technology and design to create a safer environment for drivers, pedestrians, and cyclists?</p>

    <hr>
    <h2>Observations</h2>
    <p>To gain a better understanding of current safety issues in intersections, we specifically looked at a few intersections in the city of San Diego labeled as the Fatal Fifteen. These fifteen intersections had the highest rates of accidents. By looking at the most dangerous intersections, we were able to more easily identify problems within the intersection and the causes for the high number of accidents.</p>
    <br>
    <div class="row">
        <div class="col-lg-4">
            <img src="img/wrong way.PNG" alt="wrong" style="width:240px; height:256px;">
            <p>A car made a wrong turn into a one-way street</p>
        </div>
        <div class="col-lg-4">
            <img src="img/too close.PNG" alt="wrong" style="width:240px; height:256px;">
            <p>Pedestrians/cyclists stand into the intersection</p>
        </div>
        <div class="col-lg-4">
            <img src="img/overline.PNG" alt="over" style="width:240px; height:256px;">
            <p>Car stopped over crosswalk, close call with other car</p>
        </div>
    </div> 

    <hr>
    <h2>Interviews</h2>
    <p>Through our interviews and observations at some of the Fatal Fifteen intersections, we were able to gain a few key insights about the problem. Among some of the problems we noticed in the intersection was the “busyness” of the intersection. Beyond the large number of cars, cyclists, and pedestrians, we saw firsthand how multiple modalities of travel were competing with one another. Buses, cyclists, cars turning left, cars dropping passengers off, garbage trucks, and car parking were all vying for space on the outside lanes closest to the street. In addition, we saw that in order for cars to enter parking lot entrances, they had to make 3-4 lane changes and the tight space of the intersection meant that cars often turning left on the intersection would cut almost vertically across the lanes to enter the parking lot.</p>
    <p>A few key insights we gained from interviews were that new drivers or drivers in an unfamiliar area are forced to process information from signs, nearby cars, and navigation systems and can often experience a “cognitive overload” where the sheer number of elements that drivers are expected to observe and react to are unreasonable. In addition, each stakeholder in the intersection has different priorities. A pedestrian crossing the street may be concerned with reaching their destination and crossing the street safely. However, a driver in that same intersection might have the priority of getting to work on time and not have pedestrian or cyclist safety at the forefront of their thoughts.</p>

    <hr>
    <h2>Concept Generation</h2>
    <br>
    <div class="row">
        <div class="col-lg-6">
            <img src="img/spikestoryboard.PNG" alt="bridge" width="500">
            <p>Streets would be divided in levels so pedestrians, cyclists, and drivers don't interact</p>
        </div>
        <div class="col-lg-6">
            <br>
            <img src="img/storyboardspike.PNG" alt="spike" width="500">
            <br><br><br><br>
            <p>Spikes would go up and retract from the streets to physically stop cars</p>
        </div>
    </div>
    <br>
    <p>During our concept generation process, we were focused on increasing safety for all stakeholders in the intersection. Since we found cars to be one of the most prevalent stakeholders within the intersection, we focused a lot of our concepts on cars. </p>
    <p>Some of our concepts included dividing the intersection into multiple layers and having stakeholders navigate through the intersection on multiple “levels” as to avoid any possibility of collisions from different stakeholders (i.e. cars, pedestrians, and cyclists). In the same way a multistory building increases the amount of available space, so too would dividing the intersection into multiple layers increase the amount of effective intersection space and create degrees of separation from different stakeholders with the option of further dividing those stakeholders based on direction. </p>
    <p>One focus we had during our second round of concept generation was leveraging existing technology to generate a realistic solution to our problem that could be implemented by the city at a relatively low cost. This thought inspired us to examine current innovations within the San Diego area with regards to transportation. We learned that San Diego was rolling out Smart Street Lights which were street lights with many sensors installed including a camera. We realized we could utilize machine learning and computer vision to recognize objects within the intersection. These Smart Street Lights can recognize and track objects such as cars and pedestrians and alert drivers, pedestrians, and cyclists of potential collisions and accidents by tracking their positional and directional data.</p> 
    <p>To deliver this information to primarily drivers, we decided that the best way to communicate this information to drivers would be through a heads-up display on the windshield. By ensuring that the display was overlaid onto the windshield and semi-transparent, we would 1. enable drivers to keep their eyes on the road and not look down or away, 2. allow the driver to decide what to focus on. By presenting the display on the windshield, we place the display in plain sight while remaining out of mind when unneeded. </p>

    <hr>
    <h2>Low-Fidelity Prototype</h2>
    <p>One focus we had during our second round of concept generation was leveraging existing technology to generate a realistic solution to our problem that could be implemented by the city at a relatively low cost. This thought inspired us to examine current innovations within the San Diego area with regards to transportation. We learned that San Diego was rolling out Smart Street Lights which were street lights with many sensors installed including a camera. We realized we could utilize machine learning and computer vision to recognize objects within the intersection. These Smart Street Lights can recognize and track objects such as cars and pedestrians and alert drivers, pedestrians, and cyclists of potential collisions and accidents by tracking their positional and directional data. </p>
    <p>To deliver this information to primarily drivers, we decided that the best way to communicate this information to drivers would be through a heads-up display on the windshield. By ensuring that the display was overlaid onto the windshield and semi-transparent, we would 1. enable drivers to keep their eyes on the road and not look down or away, 2. allow the driver to decide what to focus on. By presenting the display on the windshield, we place the display in plain sight while remaining out of mind when unneeded.</p>
    <div class="cent">
        <iframe src="https://drive.google.com/file/d/14VXwseScQ2Zw74JkAnAZ_Y7oF7hNu0Tc/preview" width="640" height="480"></iframe>
    </div>

    <hr> 
    <h2>Poster</h2>
    <p>For the D4SD challenge we created a poster to illustrate our problem, research, and proposed solution.</p>
    <div class="cent">
        <img src="img/arcposter.png" width="400">
    </div>

    <hr>
    <h2>Feedback</h2>
    <p>From feedback received from judges of the D4SD competition, we learned that they thought that the heads-up display would be distracting to drivers, further contributing to the cognitive overload experienced by drivers. The second point made by the judges was that our idea may be unfeasible and that the information, when displayed on the heads-up display, may not be presented in time for the driver to alter their course before a collision.</p> 
    <p>In response to the first critique, we wanted to study distractions that driver’s currently experience such as having Google Maps loaded on their phone and having to continually look for pedestrians, cars, and cyclists in addition to street signs. By comparing a prototype of our solution of a heads-up display to alternatives, we would be able to gauge how much more or less distracting our solution would be to drivers. We would measure variables such as how many times a driver took his or her eyes off the road to look at either their phone or at signs on the roads and the corresponding duration. </p>
    <p>In response to the second critique, we believe that our idea is implementable. By utilizing wireless communication technology such as Bluetooth, NFC, Wi-Fi, or any other wireless signal, these Smart Street Lights could transmit data to a data center where machine learning and computer vision algorithms are run on that data and then sent to various cars to provide them with contextual information. Self-driving car software exists and is currently being iterated on by companies such as Tesla, Waymo, and Uber and this technology could be leveraged to help process that intersection data. The software would need to be predictive and not reactive in order to provide drivers ample time to alter their course and avoid an accident or collision. One challenge we recognize in implementing our idea is putting together a team of developers who can create a network to transfer the data from San Diego’s Smart Streetlights to a data center to be processed and then sent back to cars within the intersection.</p>

    <hr>
    <h2>User Testing</h2>
    <p>We tested our design by "WOZing" our prototype with drivers. We first looked at how distracted drivers were using google maps, and then tested the effectiveness of a device that would highlight important objects in the street.</p>
    <div class="cent">
        <img src="img/160testing.PNG" alt="testing">
    </div> 
    <p>We held a phone at the front and side of the car to capture different angles. We then skyped this screen to another phone and drew over objects that we viewed as a potential threat to safety, such as another car or pedestrian. We also tried to use auditory cues such as a beeping noise if a driver was in danger.</p>
    <p>We gathered important key insights from this user testing. People rarely looked at our video, choosing to keep their eyes on the road. Beeping noises are also distracting and don't tell the driver what object to look out for, such as a pedestrian or driver. Even while using google maps, users rarely looked at the map or directions and mainly relied on the auditory information. Finally, alerts should be contextual, and not identify all objects, only potential threats.</p>
    <div class="cent">
        <iframe src="https://drive.google.com/file/d/18NgISUI2rhGxA8xAo9NlGztU_o8VvXKr/preview" width="640" height="480"></iframe>
    </div> 

    <hr>
    <h2>Redesign</h2>
    <p>Pivoting from our initial design, our team decided to take the feedback from both judges and results from our user testing and move away from the heads-up visual interface to an audio interface. From our research of how drivers currently used Google Maps, we noticed that drivers only briefly glanced at their phone screen while they were stopped at a red light and relied primarily on the audio alerts. The second pivot we made was to focus on a single goal. In our previous design, we wanted to tackle both the challenge of navigating in an unfamiliar area and safety in the intersection. In our newest design, we decided to focus solely on safety in the intersection. We designed our application in a way so that it could be run concurrently with Google Maps and could run in the background like a music application such as Spotify or Apple Music.</p>

    <hr>
    <h2>Features</h2>
    <p>Our newest design is Personal Assistant for Cars (PAC). PAC is a smartphone application that provides audio alerts to drivers when it senses an urgent emergency, i.e. an imminent collision. To determine when an imminent collision is about to occur, we are leveraging the data from San Diego’s newly installed and growing ecosystem of smart street lights. By using advance software such as image recognition, computer vision, and tracking, our software will first identify each of the parties in the intersection (i.e. car, cyclist, and pedestrian) and calculate each of their respective speeds, accelerations, and direction. Our software will specifically target outliers, those parties moving faster or accelerating faster than other parties in the intersection. In addition, our software will utilize predictive models to determine the paths of each of the parties and alert parties ahead of time so they have enough time to react and avoid collisions. One important aspect to our design is only alerting drivers of relevant information. We recognized early on that if we kept providing drivers with useless audio alerts, they would mute our system or begin to ignore our alerts which would negate our solution. Our audio alerts would only alert drivers if a crash was imminent if no course or speed was adjusted.</p>
    <div class="cent">
        <img src="img/pac.jpg" alt="final">
    </div>  

    <hr>
    <h2>Competitive Analysis</h2>
    <p>Some competitors in the space of safety are autonomous vehicles or vehicles with built-in sensors for car and object detection. However, these features are usually offered in high-end vehicles such as the Tesla Model S, making them inaccessible to the general population. In addition, our solution leverages an entire network of smart street lights that encompasses a much wider area than the near proximity of a single car.</p>

    <hr>
    <h2>Feasibility</h2>
    <p>Regarding the feasibility of our concept, we kept this at the forefront during our redesign process. We got rid all the additional hardware required for the heads-up display and had users to simply have a smartphone, download our application, and have an active data connection. We recognize that the greatest challenge for our design is developing the software, primarily backend, to predict and alert drivers of imminent collisions. However, we also know that other companies are working on projects in this space such as Waymo, Uber, and Tesla so we know that this process, while difficult, is possible. </p>
    <p>In the example scenario above, a driver in the right lane is about to make a right turn. Most drivers look to their left for oncoming traffic to determine if it is safe to turn. The shaded region represents the driver’s field of view. However, the driver does not see the cyclist to his right. Our application would utilize the data from a smart street light in the intersection to alert the driver that there is a cyclist beside him to prevent a collision. </p>

    <hr>
    <h2>Example Scenario</h2>
    <p>In the example scenario below, a driver in the right lane is about to make a right turn. Most drivers look to their left for oncoming traffic to determine if it is safe to turn. The shaded region represents the driver’s field of view. However, the driver does not see the cyclist to his right. Our application would utilize the data from a smart street light in the intersection to alert the driver that there is a cyclist beside him to prevent a collision.</p>
    <div class="cent">
        <img src="img/example.jpg" alt="example" width="400">
    </div>

    <hr> 
    <h2>Budget</h2>
    <p>The true cost is gathering a team together to develop software that not only is able to gather and interpret the data from San Diego’s Smart Streetlights but also process that data and deliver it to drivers in a timely manner. This means hiring at least a few  back-end developers and front-end developers to code the application user’s can download to their phone. Depending on the size of the team, the cost to fund such a venture could range from $100,000 a year to well over $500,000 a year.</p>
    <p>To fund such a team, we will seek funding from grants, the city of San Diego, and partnerships with businesses. Since the value of this technology and service is not limited to any single type or brand of car, we believe that car companies will be willing to fund and use this technology to integrate into their future cars. As more and more companies attempt to develop autonomous vehicles, we believe that the demand for a product like ours will only increase. It is possible that, after proving the success of this technology and usefulness of this service, be bought out by a company to integrate into their existing AV and user-interface. Some companies that would be interested in such an acquisition include but are not limited to Uber, Waymo (Alphabet), Ford, Tesla to name a few. A partnership between multiple companies may also occur in which multiple companies find value in the technology and each fund us to license and use our technology natively into their products as a way to differentiate themselves and leverage our technology as a way to distinguish their product in the marketplace.</p>

    <hr> 
    <h2>Future Steps</h2> 
    <p>For future steps for our project, we want to test this audio alert interface with drivers and observe their effectiveness and interview drivers about their experience. From there, we would begin implementing this solution by gathering video feeds from the smart street lights and developing the algorithms to first recognize parties in the intersection (i.e. cars, cyclists, pedestrian) and track their movement, speed, direction, and acceleration. Then we would develop and fine-tune predictive models to determine when parties in the intersection would crash and alert drivers.<p>
    <p>Some additional features we hope to provide is to integrate artificial intelligence into PAC and add the functionality of being to ask it questions such as: “Is it safe to make a right lane change?” In the same way we noticed that drivers when driving with another person in the car will often ask that other person to help them look behind them while backing out of a parking spot or making a lane change, so too would our solution offer contextual information to drivers when they need it.</p>
    <p>An additional feature we hope to add in the future is adapting the application for pedestrians and cyclists so that they too can be alerted when in the intersection and avoid any collisions. </p>

    <hr>
    <h2>Presentation</h2>
    <p>To illustate our concept and process, we created a presentation of our work.</p>
    <div class="cent">
        <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vTGwctSD800YmK7j-O9ujt4fjlufZbYg_b-HK84vGs_NjtyPbj_fIkpcjriwE4VNR2yofeXxAGr08Y5/embed?start=false&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    </div>

    <hr>
    <h2>Conclusion</h2>
    <p>The Mayor of San Diego, Mayor Faulconer in his support of Vision Zero in 2015 was quoted saying, “There is nothing more important than public safety which is why we’re working toward the goal of zero traffic deaths in San Diego by 2025.” We sincerely believe that our solution has the potential to make this goal a reality and make intersections safer for all parties involved. </p>
    </div>
    

    <!-- Footer -->
    <footer>
      <div class="container">
        <div class="row">
          <div class="col-md-4">
            <span class="copyright">Copyright &copy; PAC 2017</span>
          </div>
        </div>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Contact form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/agency.min.js"></script>

  </body>

</html>
